{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "acff8161-1937-40a0-bef1-9911c6ce3fd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in c:\\users\\hari prasad\\anaconda3\\lib\\site-packages (4.11.0.86)\n",
      "Requirement already satisfied: numpy in c:\\users\\hari prasad\\anaconda3\\lib\\site-packages (1.26.4)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\hari prasad\\anaconda3\\lib\\site-packages (3.9.2)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\hari prasad\\anaconda3\\lib\\site-packages (1.6.1)\n",
      "Requirement already satisfied: tensorflow in c:\\users\\hari prasad\\anaconda3\\lib\\site-packages (2.19.0)\n",
      "Requirement already satisfied: keras in c:\\users\\hari prasad\\anaconda3\\lib\\site-packages (3.10.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\hari prasad\\anaconda3\\lib\\site-packages (from matplotlib) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\hari prasad\\anaconda3\\lib\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\hari prasad\\anaconda3\\lib\\site-packages (from matplotlib) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\hari prasad\\anaconda3\\lib\\site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\hari prasad\\anaconda3\\lib\\site-packages (from matplotlib) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\hari prasad\\anaconda3\\lib\\site-packages (from matplotlib) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\hari prasad\\anaconda3\\lib\\site-packages (from matplotlib) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\hari prasad\\anaconda3\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\hari prasad\\anaconda3\\lib\\site-packages (from scikit-learn) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\hari prasad\\anaconda3\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\hari prasad\\anaconda3\\lib\\site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\hari prasad\\anaconda3\\lib\\site-packages (from tensorflow) (2.3.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\hari prasad\\anaconda3\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\hari prasad\\anaconda3\\lib\\site-packages (from tensorflow) (25.2.10)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\hari prasad\\anaconda3\\lib\\site-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\hari prasad\\anaconda3\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\hari prasad\\anaconda3\\lib\\site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\hari prasad\\anaconda3\\lib\\site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in c:\\users\\hari prasad\\anaconda3\\lib\\site-packages (from tensorflow) (4.25.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\hari prasad\\anaconda3\\lib\\site-packages (from tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\hari prasad\\anaconda3\\lib\\site-packages (from tensorflow) (75.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\hari prasad\\anaconda3\\lib\\site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\hari prasad\\anaconda3\\lib\\site-packages (from tensorflow) (3.1.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\hari prasad\\anaconda3\\lib\\site-packages (from tensorflow) (4.11.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\hari prasad\\anaconda3\\lib\\site-packages (from tensorflow) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\hari prasad\\anaconda3\\lib\\site-packages (from tensorflow) (1.71.0)\n",
      "Requirement already satisfied: tensorboard~=2.19.0 in c:\\users\\hari prasad\\anaconda3\\lib\\site-packages (from tensorflow) (2.19.0)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\hari prasad\\anaconda3\\lib\\site-packages (from tensorflow) (3.11.0)\n",
      "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in c:\\users\\hari prasad\\anaconda3\\lib\\site-packages (from tensorflow) (0.5.1)\n",
      "Requirement already satisfied: rich in c:\\users\\hari prasad\\anaconda3\\lib\\site-packages (from keras) (13.7.1)\n",
      "Requirement already satisfied: namex in c:\\users\\hari prasad\\anaconda3\\lib\\site-packages (from keras) (0.1.0)\n",
      "Requirement already satisfied: optree in c:\\users\\hari prasad\\anaconda3\\lib\\site-packages (from keras) (0.16.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\hari prasad\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.44.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\hari prasad\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hari prasad\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\hari prasad\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hari prasad\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2024.8.30)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\hari prasad\\anaconda3\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\hari prasad\\anaconda3\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\hari prasad\\anaconda3\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (3.0.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\hari prasad\\anaconda3\\lib\\site-packages (from rich->keras) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\hari prasad\\anaconda3\\lib\\site-packages (from rich->keras) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\hari prasad\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\hari prasad\\anaconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (2.1.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install opencv-python numpy matplotlib scikit-learn tensorflow keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cccc7caa-5f01-4722-81dd-efcf52b15ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# real time \n",
    "import cv2\n",
    "import os\n",
    "\n",
    "# Create directory for each label\n",
    "labels = list(\"ABCDEFGHIJKLMNOPQRSTUVWXYZ\")\n",
    "for label in labels:\n",
    "    os.makedirs(f\"data/{label}\", exist_ok=True)\n",
    "\n",
    "# Capture images\n",
    "cap = cv2.VideoCapture(0)\n",
    "count = 0\n",
    "label = \"A\"  # Change this for each letter\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    roi = frame[100:400, 100:400]\n",
    "    cv2.rectangle(frame, (100, 100), (400, 400), (255, 0, 0), 2)\n",
    "\n",
    "    cv2.imshow(\"Capture\", frame)\n",
    "    key = cv2.waitKey(1)\n",
    "\n",
    "    if key == ord(\"c\"):  # Press 'c' to capture\n",
    "        cv2.imwrite(f\"data/{label}/{count}.jpg\", roi)\n",
    "        count += 1\n",
    "    elif key == ord(\"q\"):  # Quit\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c43411a9-b962-4754-94fb-0eec9d9133ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extraction completed!\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "import os\n",
    "\n",
    "zip_path = r\"C:\\Users\\Hari prasad\\gcet\\project\\archive.zip\"  # raw string to handle backslashes\n",
    "extract_to = r\"C:\\Users\\Hari prasad\\gcet\\project\\images\"\n",
    "\n",
    "os.makedirs(extract_to, exist_ok=True)\n",
    "\n",
    "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(extract_to)\n",
    "\n",
    "print(\"Extraction completed!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4eac70d-cbe0-4ce8-a7ca-d3ee32c0a2f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels found: ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'del', 'nothing', 'space']\n",
      "Found 3000 files in A\n",
      "Found 3000 files in B\n",
      "Found 3000 files in C\n",
      "Found 3000 files in D\n",
      "Found 3000 files in E\n",
      "Found 3000 files in F\n",
      "Found 3000 files in G\n",
      "Found 3000 files in H\n",
      "Found 3000 files in I\n",
      "Found 3000 files in J\n",
      "Found 3000 files in K\n",
      "Found 3000 files in L\n",
      "Found 3000 files in M\n",
      "Found 3000 files in N\n",
      "Found 3000 files in O\n",
      "Found 3000 files in P\n",
      "Found 3000 files in Q\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "data_dir = r\"C:\\Users\\Hari prasad\\gcet\\project\\images\\asl_alphabet_train\\asl_alphabet_train\"\n",
    "labels = sorted(os.listdir(data_dir))\n",
    "print(\"Labels found:\", labels)\n",
    "\n",
    "X, y = [], []\n",
    "total_images = 0\n",
    "\n",
    "for idx, label in enumerate(labels):\n",
    "    folder = os.path.join(data_dir, label)\n",
    "    if not os.path.isdir(folder):\n",
    "        print(f\"Skipping {folder}, not a directory\")\n",
    "        continue\n",
    "    files = os.listdir(folder)\n",
    "    print(f\"Found {len(files)} files in {label}\")\n",
    "    for img_file in files:\n",
    "        img_path = os.path.join(folder, img_file)\n",
    "        img = cv2.imread(img_path)\n",
    "        if img is None:\n",
    "            print(f\"Warning: Could not read image {img_path}\")\n",
    "            continue\n",
    "        img = cv2.resize(img, (64, 64))\n",
    "        X.append(img)\n",
    "        y.append(idx)\n",
    "        total_images += 1\n",
    "\n",
    "print(f\"Total images loaded: {total_images}\")\n",
    "\n",
    "if total_images == 0:\n",
    "    raise ValueError(\"No images were loaded. Please check your dataset folder and files.\")\n",
    "\n",
    "X = np.array(X, dtype='float32') / 255.0\n",
    "y = to_categorical(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"Dataset loaded and split:\")\n",
    "print(\"Training samples:\", X_train.shape[0])\n",
    "print(\"Testing samples:\", X_test.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd34523-006e-4736-9ffb-741c53f98da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f250818-a447-44c3-84b7-010c53c5a7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining\n",
    "num_classes = len(labels)  # Should be 29 for A-Z + del/nothing/space\n",
    "\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(64, 64, 3)),\n",
    "    MaxPooling2D(2, 2),\n",
    "    \n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(2, 2),\n",
    "    \n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(2, 2),\n",
    "    \n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b335f15-e6ef-4fbb-b862-94273a17b808",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training the model\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=25,\n",
    "    batch_size=64,\n",
    "    validation_split=0.1,\n",
    "    verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd1dd79-0588-4a9c-afc2-3cb3a92432e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on test data\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "print(f\"Test accuracy: {test_acc * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "730187a2-c0cb-498f-88da-d9f8e6e2ae4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Save the trained model\n",
    "model.save(\"sign_language_model.keras\")\n",
    "print(\"Model saved as sign_language_model.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2387e915-83a0-4090-8d69-35a643cd343c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model = load_model(\"sign_language_model.keras\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "438da083-fd6e-45a8-aef8-533bdef39424",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image_path = r\"C:\\Users\\Hari prasad\\gcet\\project\\images\\asl_alphabet_train\\asl_alphabet_train\\B\\B1.jpg\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a4c334f-97e2-49d0-b6bf-79eb5ab42b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from keras.models import load_model\n",
    "\n",
    "# Load your trained model\n",
    "model = load_model(\"sign_language_model.h5\")\n",
    "\n",
    "# Label list (same order as during training)\n",
    "labels = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N',\n",
    "          'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z',\n",
    "          'del', 'nothing', 'space']\n",
    "\n",
    "# Path to a single test image\n",
    "test_image_path = r\"C:\\Users\\Hari prasad\\gcet\\project\\images\\asl_alphabet_train\\asl_alphabet_train\\B\\B1.jpg\"\n",
    "\n",
    "# Load and preprocess image\n",
    "img = cv2.imread(test_image_path)\n",
    "img = cv2.resize(img, (64, 64))      # same size as used in training\n",
    "img = img.astype('float32') / 255.0  # normalize\n",
    "img = np.expand_dims(img, axis=0)    # make it (1, 64, 64, 3)\n",
    "\n",
    "# Predict\n",
    "pred = model.predict(img)\n",
    "predicted_class = labels[np.argmax(pred)]\n",
    "\n",
    "print(\"Predicted Sign:\", predicted_class)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0486e0cd-4a5f-40fb-92a0-9a3bce9250ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spell Out Words Using Multiple Letters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c53a791-b400-4b24-bb81-08acb7f00f3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from keras.models import load_model\n",
    "\n",
    "# Load trained model\n",
    "model = load_model(\"sign_language_model.h5\")\n",
    "\n",
    "# Label list (must match training order)\n",
    "labels = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N',\n",
    "          'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z',\n",
    "          'del', 'nothing', 'space']\n",
    "\n",
    "# Start webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Could not open webcam.\")\n",
    "    exit()\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Failed to grab frame\")\n",
    "        break\n",
    "\n",
    "    # Flip the frame for a mirror view\n",
    "    frame = cv2.flip(frame, 1)\n",
    "\n",
    "    # Define larger ROI box (350x350 px)\n",
    "    x1, y1 = 100, 100\n",
    "    x2, y2 = x1 + 350, y1 + 350\n",
    "    roi = frame[y1:y2, x1:x2]\n",
    "\n",
    "    # Preprocess ROI\n",
    "    img = cv2.resize(roi, (64, 64))\n",
    "    img = img.astype('float32') / 255.0\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "\n",
    "    # Predict\n",
    "    pred = model.predict(img, verbose=0)\n",
    "    predicted_label = labels[np.argmax(pred)]\n",
    "    confidence = np.max(pred)\n",
    "\n",
    "    # Draw ROI box\n",
    "    cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "\n",
    "    # Show prediction only if confidence > threshold\n",
    "    if confidence > 0.5:\n",
    "        display_text = f\"{predicted_label} ({confidence:.2f})\"\n",
    "    else:\n",
    "        display_text = \"Detecting...\"\n",
    "\n",
    "    # Display prediction text\n",
    "    cv2.putText(frame, display_text, (x1, y1 - 15),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "\n",
    "    # Show the frame\n",
    "    cv2.imshow(\"Sign Language Detection\", frame)\n",
    "\n",
    "    # Press 'q' to exit\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Clean up\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7943f30b-9500-4837-92b6-e5b248268733",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder: asl_alphabet_test\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "test_dir = r\"C:\\Users\\Hari prasad\\gcet\\project\\images\\asl_alphabet_test\"\n",
    "\n",
    "for item in os.listdir(test_dir):\n",
    "    path = os.path.join(test_dir, item)\n",
    "    if os.path.isdir(path):\n",
    "        print(f\"Folder: {item}\")\n",
    "    else:\n",
    "        print(f\"File: {item}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "84e62896-2117-4e45-8f3d-6186abd562a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step\n",
      "A_test.jpg in asl_alphabet_test → Predicted: A (1.00)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "B_test.jpg in asl_alphabet_test → Predicted: B (1.00)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "C_test.jpg in asl_alphabet_test → Predicted: C (1.00)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "D_test.jpg in asl_alphabet_test → Predicted: D (1.00)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "E_test.jpg in asl_alphabet_test → Predicted: E (1.00)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "F_test.jpg in asl_alphabet_test → Predicted: F (1.00)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "G_test.jpg in asl_alphabet_test → Predicted: G (1.00)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "H_test.jpg in asl_alphabet_test → Predicted: H (1.00)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "I_test.jpg in asl_alphabet_test → Predicted: I (1.00)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "J_test.jpg in asl_alphabet_test → Predicted: J (1.00)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "K_test.jpg in asl_alphabet_test → Predicted: K (1.00)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "L_test.jpg in asl_alphabet_test → Predicted: L (1.00)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "M_test.jpg in asl_alphabet_test → Predicted: M (1.00)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "nothing_test.jpg in asl_alphabet_test → Predicted: nothing (1.00)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "N_test.jpg in asl_alphabet_test → Predicted: N (1.00)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "O_test.jpg in asl_alphabet_test → Predicted: O (1.00)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "P_test.jpg in asl_alphabet_test → Predicted: P (1.00)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "Q_test.jpg in asl_alphabet_test → Predicted: Q (1.00)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "R_test.jpg in asl_alphabet_test → Predicted: R (1.00)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "space_test.jpg in asl_alphabet_test → Predicted: space (1.00)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "S_test.jpg in asl_alphabet_test → Predicted: S (1.00)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "T_test.jpg in asl_alphabet_test → Predicted: T (1.00)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "U_test.jpg in asl_alphabet_test → Predicted: U (1.00)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "V_test.jpg in asl_alphabet_test → Predicted: V (1.00)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "W_test.jpg in asl_alphabet_test → Predicted: W (1.00)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "X_test.jpg in asl_alphabet_test → Predicted: X (1.00)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "Y_test.jpg in asl_alphabet_test → Predicted: Y (1.00)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "Z_test.jpg in asl_alphabet_test → Predicted: Z (1.00)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from keras.models import load_model\n",
    "\n",
    "model = load_model(\"sign_language_model.h5\")\n",
    "\n",
    "labels = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N',\n",
    "          'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z',\n",
    "          'del', 'nothing', 'space']\n",
    "\n",
    "test_dir = r\"C:\\Users\\Hari prasad\\gcet\\project\\images\\asl_alphabet_test\"\n",
    "valid_extensions = ['.jpg', '.jpeg', '.png']\n",
    "\n",
    "for label_folder in os.listdir(test_dir):\n",
    "    folder_path = os.path.join(test_dir, label_folder)\n",
    "    if not os.path.isdir(folder_path):\n",
    "        print(f\"Skipping non-folder: {label_folder}\")\n",
    "        continue\n",
    "\n",
    "    for img_file in os.listdir(folder_path):\n",
    "        if not any(img_file.lower().endswith(ext) for ext in valid_extensions):\n",
    "            print(f\"Skipping non-image file: {img_file}\")\n",
    "            continue\n",
    "\n",
    "        img_path = os.path.join(folder_path, img_file)\n",
    "        img = cv2.imread(img_path)\n",
    "        if img is None:\n",
    "            print(f\"Skipping unreadable file: {img_file}\")\n",
    "            continue\n",
    "\n",
    "        img = cv2.resize(img, (64, 64))\n",
    "        img = img.astype('float32') / 255.0\n",
    "        img = np.expand_dims(img, axis=0)\n",
    "\n",
    "        pred = model.predict(img)\n",
    "        predicted_label = labels[np.argmax(pred)]\n",
    "        confidence = np.max(pred)\n",
    "\n",
    "        print(f\"{img_file} in {label_folder} → Predicted: {predicted_label} ({confidence:.2f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "700c9de5-6819-48d0-856e-922ffda63cce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "test_dir = r\"C:\\Your\\Correct\\Path\\Here\"\n",
    "print(os.path.exists(test_dir))  # Should print True now\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a84c767c-8836-416b-9380-bbb8dec27c32",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: 'C:\\\\Users\\\\Hari prasad\\\\gcet\\\\asl_alphabet_test'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 17\u001b[0m\n\u001b[0;32m     14\u001b[0m correct \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     15\u001b[0m total \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m---> 17\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m label_folder \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39mlistdir(test_dir):\n\u001b[0;32m     18\u001b[0m     folder_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(test_dir, label_folder)\n\u001b[0;32m     19\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misdir(folder_path):\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: 'C:\\\\Users\\\\Hari prasad\\\\gcet\\\\asl_alphabet_test'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from keras.models import load_model\n",
    "\n",
    "model = load_model(\"sign_language_model.h5\")\n",
    "labels = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N',\n",
    "          'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z',\n",
    "          'del', 'nothing', 'space']\n",
    "\n",
    "test_dir = r\"C:\\Users\\Hari prasad\\gcet\\asl_alphabet_test\"\n",
    "valid_extensions = ['.jpg', '.jpeg', '.png']\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "for label_folder in os.listdir(test_dir):\n",
    "    folder_path = os.path.join(test_dir, label_folder)\n",
    "    if not os.path.isdir(folder_path):\n",
    "        continue\n",
    "\n",
    "    for img_file in os.listdir(folder_path):\n",
    "        if not any(img_file.lower().endswith(ext) for ext in valid_extensions):\n",
    "            continue\n",
    "\n",
    "        img_path = os.path.join(folder_path, img_file)\n",
    "        img = cv2.imread(img_path)\n",
    "        if img is None:\n",
    "            continue\n",
    "\n",
    "        img = cv2.resize(img, (64, 64))\n",
    "        img = img.astype('float32') / 255.0\n",
    "        img = np.expand_dims(img, axis=0)\n",
    "\n",
    "        pred = model.predict(img)\n",
    "        predicted_label = labels[np.argmax(pred)]\n",
    "\n",
    "        print(f\"{img_file} in {label_folder} → Predicted: {predicted_label} ({np.max(pred):.2f})\")\n",
    "\n",
    "        total += 1\n",
    "        if predicted_label.lower() == label_folder.lower():\n",
    "            correct += 1\n",
    "\n",
    "print(f\"Test accuracy: {correct}/{total} = {correct / total * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6bc69bf3-15b3-47b5-93a1-9899def56228",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: 'C:\\\\Users\\\\Hari prasad\\\\gcet\\\\asl_alphabet_test'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m correct \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m      2\u001b[0m total \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m label_folder \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39mlistdir(test_dir):\n\u001b[0;32m      5\u001b[0m     folder_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(test_dir, label_folder)\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misdir(folder_path):\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: 'C:\\\\Users\\\\Hari prasad\\\\gcet\\\\asl_alphabet_test'"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "for label_folder in os.listdir(test_dir):\n",
    "    folder_path = os.path.join(test_dir, label_folder)\n",
    "    if not os.path.isdir(folder_path):\n",
    "        continue\n",
    "\n",
    "    for img_file in os.listdir(folder_path):\n",
    "        if not any(img_file.lower().endswith(ext) for ext in valid_extensions):\n",
    "            continue\n",
    "\n",
    "        img_path = os.path.join(folder_path, img_file)\n",
    "        img = cv2.imread(img_path)\n",
    "        if img is None:\n",
    "            continue\n",
    "\n",
    "        img = cv2.resize(img, (64, 64))\n",
    "        img = img.astype('float32') / 255.0\n",
    "        img = np.expand_dims(img, axis=0)\n",
    "\n",
    "        pred = model.predict(img)\n",
    "        predicted_label = labels[np.argmax(pred)]\n",
    "\n",
    "        total += 1\n",
    "        if predicted_label == label_folder:\n",
    "            correct += 1\n",
    "\n",
    "print(f\"Test accuracy: {correct}/{total} = {correct / total * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "efb6eefc-f5a2-4808-bb12-5c7d254d8f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# happy ,hello,thankyou "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a6843020-64f7-4674-93b8-36f1fa2c0553",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from keras.models import load_model\n",
    "\n",
    "# Load the trained model\n",
    "model = load_model(\"sign_language_model.h5\")\n",
    "\n",
    "# Labels (must match training)\n",
    "labels = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N',\n",
    "          'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z',\n",
    "          'del', 'nothing', 'space']\n",
    "\n",
    "# Webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# For building words\n",
    "current_word = \"\"\n",
    "last_predicted = \"\"\n",
    "frame_count = 0\n",
    "PREDICTION_DELAY = 30  # Number of frames to wait before registering next letter\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Flip camera horizontally (mirror effect)\n",
    "    frame = cv2.flip(frame, 1)\n",
    "\n",
    "    # ROI on LEFT (appears on right side in mirror view)\n",
    "    x1, y1, x2, y2 = 50, 100, 250, 300\n",
    "    roi = frame[y1:y2, x1:x2]\n",
    "\n",
    "    # Preprocess ROI\n",
    "    img = cv2.resize(roi, (64, 64))\n",
    "    img = img.astype('float32') / 255.0\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "\n",
    "    # Predict\n",
    "    pred = model.predict(img, verbose=0)\n",
    "    predicted_label = labels[np.argmax(pred)]\n",
    "    confidence = np.max(pred)\n",
    "\n",
    "    # Add to word if stable\n",
    "    if predicted_label != last_predicted:\n",
    "        frame_count = 0\n",
    "    else:\n",
    "        frame_count += 1\n",
    "        if frame_count > PREDICTION_DELAY:\n",
    "            if predicted_label not in ['nothing', 'del']:\n",
    "                current_word += predicted_label\n",
    "            elif predicted_label == 'space':\n",
    "                current_word += ' '\n",
    "            elif predicted_label == 'del' and len(current_word) > 0:\n",
    "                current_word = current_word[:-1]\n",
    "            frame_count = 0\n",
    "\n",
    "    last_predicted = predicted_label\n",
    "\n",
    "    # Draw ROI box and predictions\n",
    "    cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "    cv2.putText(frame, f\"Letter: {predicted_label} ({confidence:.2f})\", (x1, y1 - 10),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "    cv2.putText(frame, f\"Word: {current_word}\", (x1, y2 + 40),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 1.0, (255, 255, 255), 2)\n",
    "\n",
    "    cv2.imshow(\"Sign Language Detection\", frame)\n",
    "\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    if key == ord('c'):\n",
    "        current_word = \"\"\n",
    "    elif key == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "287e86b2-bd20-469a-8f89-0819fc6f4b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# design gui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "acbe705c-520a-41dc-bc4e-cea25fd90183",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opencv-python-headless\n",
      "  Downloading opencv_python_headless-4.11.0.86-cp37-abi3-win_amd64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\hari prasad\\anaconda3\\lib\\site-packages (1.26.4)\n",
      "Requirement already satisfied: keras in c:\\users\\hari prasad\\anaconda3\\lib\\site-packages (3.10.0)\n",
      "Requirement already satisfied: tensorflow in c:\\users\\hari prasad\\anaconda3\\lib\\site-packages (2.19.0)\n",
      "Requirement already satisfied: pillow in c:\\users\\hari prasad\\anaconda3\\lib\\site-packages (10.4.0)\n",
      "Requirement already satisfied: absl-py in c:\\users\\hari prasad\\anaconda3\\lib\\site-packages (from keras) (2.3.0)\n",
      "Requirement already satisfied: rich in c:\\users\\hari prasad\\anaconda3\\lib\\site-packages (from keras) (13.7.1)\n",
      "Requirement already satisfied: namex in c:\\users\\hari prasad\\anaconda3\\lib\\site-packages (from keras) (0.1.0)\n",
      "Requirement already satisfied: h5py in c:\\users\\hari prasad\\anaconda3\\lib\\site-packages (from keras) (3.11.0)\n",
      "Requirement already satisfied: optree in c:\\users\\hari prasad\\anaconda3\\lib\\site-packages (from keras) (0.16.0)\n",
      "Requirement already satisfied: ml-dtypes in c:\\users\\hari prasad\\anaconda3\\lib\\site-packages (from keras) (0.5.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\hari prasad\\anaconda3\\lib\\site-packages (from keras) (24.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\hari prasad\\anaconda3\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\hari prasad\\anaconda3\\lib\\site-packages (from tensorflow) (25.2.10)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\hari prasad\\anaconda3\\lib\\site-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\hari prasad\\anaconda3\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\hari prasad\\anaconda3\\lib\\site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\hari prasad\\anaconda3\\lib\\site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in c:\\users\\hari prasad\\anaconda3\\lib\\site-packages (from tensorflow) (4.25.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\hari prasad\\anaconda3\\lib\\site-packages (from tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\hari prasad\\anaconda3\\lib\\site-packages (from tensorflow) (75.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\hari prasad\\anaconda3\\lib\\site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\hari prasad\\anaconda3\\lib\\site-packages (from tensorflow) (3.1.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\hari prasad\\anaconda3\\lib\\site-packages (from tensorflow) (4.11.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\hari prasad\\anaconda3\\lib\\site-packages (from tensorflow) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\hari prasad\\anaconda3\\lib\\site-packages (from tensorflow) (1.71.0)\n",
      "Requirement already satisfied: tensorboard~=2.19.0 in c:\\users\\hari prasad\\anaconda3\\lib\\site-packages (from tensorflow) (2.19.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\hari prasad\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.44.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\hari prasad\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hari prasad\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\hari prasad\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hari prasad\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2024.8.30)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\hari prasad\\anaconda3\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\hari prasad\\anaconda3\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\hari prasad\\anaconda3\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (3.0.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\hari prasad\\anaconda3\\lib\\site-packages (from rich->keras) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\hari prasad\\anaconda3\\lib\\site-packages (from rich->keras) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\hari prasad\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\hari prasad\\anaconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (2.1.3)\n",
      "Downloading opencv_python_headless-4.11.0.86-cp37-abi3-win_amd64.whl (39.4 MB)\n",
      "   ---------------------------------------- 0.0/39.4 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 3.7/39.4 MB 19.9 MB/s eta 0:00:02\n",
      "   ---- ----------------------------------- 4.7/39.4 MB 12.4 MB/s eta 0:00:03\n",
      "   ----- ---------------------------------- 5.5/39.4 MB 8.8 MB/s eta 0:00:04\n",
      "   ------ --------------------------------- 6.3/39.4 MB 7.7 MB/s eta 0:00:05\n",
      "   ------- -------------------------------- 7.6/39.4 MB 7.3 MB/s eta 0:00:05\n",
      "   -------- ------------------------------- 8.7/39.4 MB 7.2 MB/s eta 0:00:05\n",
      "   --------- ------------------------------ 9.7/39.4 MB 6.8 MB/s eta 0:00:05\n",
      "   ---------- ----------------------------- 10.7/39.4 MB 6.5 MB/s eta 0:00:05\n",
      "   ----------- ---------------------------- 11.3/39.4 MB 6.2 MB/s eta 0:00:05\n",
      "   ------------ --------------------------- 12.1/39.4 MB 5.9 MB/s eta 0:00:05\n",
      "   ------------- -------------------------- 13.4/39.4 MB 5.9 MB/s eta 0:00:05\n",
      "   -------------- ------------------------- 14.4/39.4 MB 5.8 MB/s eta 0:00:05\n",
      "   --------------- ------------------------ 15.5/39.4 MB 5.7 MB/s eta 0:00:05\n",
      "   ---------------- ----------------------- 16.3/39.4 MB 5.7 MB/s eta 0:00:05\n",
      "   ----------------- ---------------------- 17.0/39.4 MB 5.5 MB/s eta 0:00:05\n",
      "   ------------------ --------------------- 18.6/39.4 MB 5.6 MB/s eta 0:00:04\n",
      "   ------------------- -------------------- 19.4/39.4 MB 5.6 MB/s eta 0:00:04\n",
      "   --------------------- ------------------ 21.0/39.4 MB 5.6 MB/s eta 0:00:04\n",
      "   ---------------------- ----------------- 22.0/39.4 MB 5.6 MB/s eta 0:00:04\n",
      "   ---------------------- ----------------- 22.5/39.4 MB 5.5 MB/s eta 0:00:04\n",
      "   ----------------------- ---------------- 23.6/39.4 MB 5.4 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 24.9/39.4 MB 5.4 MB/s eta 0:00:03\n",
      "   -------------------------- ------------- 25.7/39.4 MB 5.4 MB/s eta 0:00:03\n",
      "   -------------------------- ------------- 26.5/39.4 MB 5.3 MB/s eta 0:00:03\n",
      "   --------------------------- ------------ 27.5/39.4 MB 5.3 MB/s eta 0:00:03\n",
      "   ----------------------------- ---------- 28.6/39.4 MB 5.3 MB/s eta 0:00:03\n",
      "   ------------------------------ --------- 29.6/39.4 MB 5.3 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 30.4/39.4 MB 5.2 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 31.2/39.4 MB 5.2 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 32.0/39.4 MB 5.1 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 33.3/39.4 MB 5.2 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 34.3/39.4 MB 5.2 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 35.7/39.4 MB 5.2 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 36.4/39.4 MB 5.1 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 37.7/39.4 MB 5.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  39.1/39.4 MB 5.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 39.4/39.4 MB 5.2 MB/s eta 0:00:00\n",
      "Installing collected packages: opencv-python-headless\n",
      "Successfully installed opencv-python-headless-4.11.0.86\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install opencv-python-headless numpy keras tensorflow pillow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73e2fdfa-de75-4b93-97eb-22c17bf997c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyttsx3\n",
      "  Downloading pyttsx3-2.98-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting comtypes (from pyttsx3)\n",
      "  Downloading comtypes-1.4.11-py3-none-any.whl.metadata (7.2 kB)\n",
      "Collecting pypiwin32 (from pyttsx3)\n",
      "  Downloading pypiwin32-223-py3-none-any.whl.metadata (236 bytes)\n",
      "Requirement already satisfied: pywin32 in c:\\users\\hari prasad\\anaconda3\\lib\\site-packages (from pyttsx3) (305.1)\n",
      "Downloading pyttsx3-2.98-py3-none-any.whl (34 kB)\n",
      "Downloading comtypes-1.4.11-py3-none-any.whl (246 kB)\n",
      "Downloading pypiwin32-223-py3-none-any.whl (1.7 kB)\n",
      "Installing collected packages: pypiwin32, comtypes, pyttsx3\n",
      "Successfully installed comtypes-1.4.11 pypiwin32-223 pyttsx3-2.98\n"
     ]
    }
   ],
   "source": [
    "!pip install pyttsx3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d43815ab-920e-4f7b-a41d-63f63e23fd72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "11b61a10-7a14-4aae-b9ff-9a6a311f6c9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from keras.models import load_model\n",
    "import tkinter as tk\n",
    "from tkinter import Label, Button\n",
    "from PIL import Image, ImageTk\n",
    "import pyttsx3\n",
    "\n",
    "# Load model and labels\n",
    "model = load_model(\"sign_language_model.h5\")\n",
    "labels = list(\"ABCDEFGHIJKLMNOPQRSTUVWXYZ\") + ['del', 'nothing', 'space']\n",
    "\n",
    "# TTS setup\n",
    "engine = pyttsx3.init()\n",
    "\n",
    "# GUI Setup\n",
    "root = tk.Tk()\n",
    "root.title(\"ASL Translator\")\n",
    "root.geometry(\"850x650\")\n",
    "root.configure(bg=\"#f0f0f0\")\n",
    "\n",
    "# Variables\n",
    "current_word = \"\"\n",
    "last_predicted = \"\"\n",
    "frame_count = 0\n",
    "PREDICTION_DELAY = 20\n",
    "CONFIDENCE_THRESHOLD = 0.9\n",
    "\n",
    "# Webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Functions\n",
    "def update_frame():\n",
    "    global frame_count, last_predicted, current_word\n",
    "\n",
    "    ret, frame = cap.read()\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    x1, y1, x2, y2 = 100, 100, 450, 450\n",
    "    roi = frame[y1:y2, x1:x2]\n",
    "\n",
    "    # Preprocess\n",
    "    img = cv2.resize(roi, (64, 64)).astype(\"float32\") / 255.0\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "\n",
    "    # Predict\n",
    "    pred = model.predict(img, verbose=0)\n",
    "    predicted_label = labels[np.argmax(pred)]\n",
    "    confidence = np.max(pred)\n",
    "\n",
    "    # Update if stable and confident\n",
    "    if confidence > CONFIDENCE_THRESHOLD:\n",
    "        if predicted_label == last_predicted:\n",
    "            frame_count += 1\n",
    "        else:\n",
    "            frame_count = 0\n",
    "        if frame_count >= PREDICTION_DELAY:\n",
    "            if predicted_label == \"space\":\n",
    "                current_word += \" \"\n",
    "            elif predicted_label == \"del\":\n",
    "                current_word = current_word[:-1]\n",
    "            elif predicted_label != \"nothing\":\n",
    "                current_word += predicted_label\n",
    "                engine.say(predicted_label)  # Speak the letter\n",
    "                engine.runAndWait()\n",
    "            frame_count = 0\n",
    "        last_predicted = predicted_label\n",
    "    else:\n",
    "        last_predicted = \"\"\n",
    "        frame_count = 0\n",
    "\n",
    "    # Show webcam with ROI\n",
    "    cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "    img_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    img_pil = Image.fromarray(img_rgb)\n",
    "    img_tk = ImageTk.PhotoImage(img_pil)\n",
    "\n",
    "    webcam_label.imgtk = img_tk\n",
    "    webcam_label.configure(image=img_tk)\n",
    "\n",
    "    letter_var.set(f\"Letter: {predicted_label} ({confidence:.2f})\")\n",
    "    word_var.set(f\"Translation: {current_word}\")\n",
    "\n",
    "    root.after(10, update_frame)\n",
    "\n",
    "def clear_text():\n",
    "    global current_word\n",
    "    current_word = \"\"\n",
    "    word_var.set(\"Translation: \")\n",
    "\n",
    "def speak_text():\n",
    "    if current_word.strip():\n",
    "        engine.say(current_word.strip())\n",
    "        engine.runAndWait()\n",
    "\n",
    "def close():\n",
    "    cap.release()\n",
    "    root.destroy()\n",
    "\n",
    "# GUI Components\n",
    "webcam_label = Label(root)\n",
    "webcam_label.pack()\n",
    "\n",
    "letter_var = tk.StringVar()\n",
    "word_var = tk.StringVar()\n",
    "\n",
    "label1 = Label(root, textvariable=letter_var, font=(\"Arial\", 20), bg=\"#f0f0f0\", fg=\"green\")\n",
    "label1.pack(pady=10)\n",
    "\n",
    "label2 = Label(root, textvariable=word_var, font=(\"Arial\", 20), bg=\"#f0f0f0\")\n",
    "label2.pack(pady=10)\n",
    "\n",
    "clear_button = Button(root, text=\"Clear\", command=clear_text, font=(\"Arial\", 14), bg=\"orange\", fg=\"black\")\n",
    "clear_button.pack(pady=5)\n",
    "\n",
    "speak_button = Button(root, text=\"Speak\", command=speak_text, font=(\"Arial\", 14), bg=\"blue\", fg=\"white\")\n",
    "speak_button.pack(pady=5)\n",
    "\n",
    "exit_button = Button(root, text=\"Exit\", command=close, font=(\"Arial\", 14), bg=\"black\", fg=\"white\")\n",
    "exit_button.pack(pady=5)\n",
    "\n",
    "# Start\n",
    "update_frame()\n",
    "root.mainloop()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
